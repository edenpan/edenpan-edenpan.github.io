<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Deep Learning on Apache Spark 翻译 | Eden</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Deep Learning on Apache Spark翻译自：https://deeplearning4j.org/spark#localityDeep learning 是计算密集的，所以有非常大的数据，计算速度。你可以处理这个问题使用很快的硬件，通常是GPU,优化代码和一些形式的并行。数据并行性使大型数据集称为碎片并把这些碎片交给神经网络分离，比如每个神经网络都在自己的核心上。Deeple">
<meta name="keywords" content="deeplearning4j; spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning on Apache Spark 翻译">
<meta property="og:url" content="http://blog.sevenpan.com/2018/04/15/Deep Learning on Apache Spark/index.html">
<meta property="og:site_name" content="Eden">
<meta property="og:description" content="Deep Learning on Apache Spark翻译自：https://deeplearning4j.org/spark#localityDeep learning 是计算密集的，所以有非常大的数据，计算速度。你可以处理这个问题使用很快的硬件，通常是GPU,优化代码和一些形式的并行。数据并行性使大型数据集称为碎片并把这些碎片交给神经网络分离，比如每个神经网络都在自己的核心上。Deeple">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-10-13T15:00:59.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Learning on Apache Spark 翻译">
<meta name="twitter:description" content="Deep Learning on Apache Spark翻译自：https://deeplearning4j.org/spark#localityDeep learning 是计算密集的，所以有非常大的数据，计算速度。你可以处理这个问题使用很快的硬件，通常是GPU,优化代码和一些形式的并行。数据并行性使大型数据集称为碎片并把这些碎片交给神经网络分离，比如每个神经网络都在自己的核心上。Deeple">
  
    <link rel="alternate" href="/atom.xml" title="Eden" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Eden</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://blog.sevenpan.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Deep Learning on Apache Spark" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/15/Deep Learning on Apache Spark/" class="article-date">
  <time datetime="2018-04-15T04:41:12.000Z" itemprop="datePublished">2018-04-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Deep Learning on Apache Spark 翻译
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Deep-Learning-on-Apache-Spark"><a href="#Deep-Learning-on-Apache-Spark" class="headerlink" title="Deep Learning on Apache Spark"></a>Deep Learning on Apache Spark</h1><p>翻译自：<a href="https://deeplearning4j.org/spark#locality" target="_blank" rel="noopener">https://deeplearning4j.org/spark#locality</a><br>Deep learning 是计算密集的，所以有非常大的数据，计算速度。你可以处理这个问题使用很快的硬件，通常是GPU,优化代码和一些形式的并行。<br>数据并行性使大型数据集称为碎片并把这些碎片交给神经网络分离，比如每个神经网络都在自己的核心上。Deeplearning4j依靠spark来处理这些，并发训练模型并且迭代平均它们在中心模型所产生的参数。（模型并发，在<a href="https://static.googleusercontent.com/media/research.google.com/en//archive/large_deep_networks_nips2012.pdf" target="_blank" rel="noopener">here</a>被讨论了，允许使用模型在不同的大数据集上使用而无需被平均）<br>注意如果你需要一个参数服务器基础的方法（需要更多的步骤），可以查看<a href="https://deeplearning4j.org/distributed" target="_blank" rel="noopener">分发页面</a>.</p>
<h2 id="Overview-概述"><a href="#Overview-概述" class="headerlink" title="Overview 概述"></a>Overview 概述</h2><p>Deeplearning4j支持在Spark集群上训练神经网络，为了加速网络训练。<br>和DL4J的MultiLayerNetwork和ComputationGraph类相同，DL4J定义了两个类用于在Spark上训练神经网络。  </p>
<ol>
<li>SparkDl4jMultiLayer 一个围绕MultiLayerNetwork的包装类</li>
<li>SparkComputationGraph 一个围绕ComputationGraph的包装类</li>
</ol>
<p>由于这两个类时围绕标准的单机类包装的，这个网络配置过程对于标准的和分布式的训练都是相同的。在Spark上分布式训练和本地训练有两个不同的地方，1.数据是如何加载的，和训练是如何启动的（需要一些额外的集群配置）。<br>一个标准的在Spark集群上训练网络的工作流程如下：  </p>
<ol>
<li><p>创造你自己的神经网络训练类。通常来说，包含为以下工作所做的代码：<br> 指定你自己的神经网络配置（MultiLayerConfiguration或者ComputationGraphConfiguration），和你为单机训练所配置的那样。<br> 创造一个TrainingMaster的实例：这个指定了分布式训练会如何在实际中进行。<br> 加载你自己的训练数据。这里有很多方法来加载数据，有不同的权衡；更多的细节将会在之后的文档中讨论。<br> 调用合适的fit方法在SparkDl4jMultiLayer或者SparkComputationGraph实例中。<br> 保存或者使用训练的网络（这个训练的MultiLayerNetwork或者ComputationGraph实例）  </p>
</li>
<li><p>将你的jar打包等候spark提交。<br> 如果使用maven，运行“mvn package -DskipTests”是一个方法</p>
</li>
<li><p>调用Spark提交，并且启动你集群使用合适的配置。</p>
</li>
</ol>
<p>注意对一个单独机器的训练，Spark locak可以在DL4J上使用，尽管这不推荐（因为同步化和序列化在spark上的过度使用）。替代的，可以考虑使用以下：  </p>
<ol>
<li>对于一个单机CPU/GPU系统，使用标准的MultiLayerNetwork或者ComputationGraph训练。  </li>
<li>对于多个CPU／GPU系统，使用ParallelWrapper. 这个功能上等于运行spark在本地模式，尽管有更低的开销（从而有更好的训练表现）。</li>
</ol>
<h2 id="How-Distributed-Network-Training-Occurs-with-DL4J-on-Spark"><a href="#How-Distributed-Network-Training-Occurs-with-DL4J-on-Spark" class="headerlink" title="How Distributed Network Training Occurs with DL4J on Spark"></a>How Distributed Network Training Occurs with DL4J on Spark</h2><p>分布式神经网络是如何在DL4J上训练的<br>当前的DL4J版本使用的参数平均的过程在训练一个网络的时候。未来的版本可能会加入其他分布式网络训练方法。<br>The process of training a network using parameter averaging is conceptually quite simple:<br>训练一个网络使用参数平均的过程在概念上很简单： </p>
<ol>
<li>Master（spark driven）开始一个初始化的网络配置和参数</li>
<li>数据被切分为很多子集，基于TrainingMaster的配置</li>
<li>在这些数据切片上迭代。对每一个训练数据的切片：<br> 将参数，配置（如果适当的，对于momentum/rmsprop/adagrad的网络更新状态）从master给到每一个worker中。<br> 在每一个切片的一部分适配每一个worker<br> 平均参数（如果可能，更新状态）并且返回评价结果到mater中。</li>
<li>训练结束，master有一个已经训练好的模型网络。  </li>
</ol>
<p>比如，下图展示了5个worker参数平均的过程一个每一个参数均衡频率是1.就像一个离线的训练，一个训练数据集被切割为一系列的数据子集（通常被认为是minibatch，在非分布式设置中）；在每一个split中训练过程，每一个worker获得这个切片的一个子集。在实际中，这个切片的个数是被自动决定的，基于训练配置（基于worker的数量，平均的频率和worker minibatch Size）。<br><a href="https://deeplearning4j.org/img/parameter_averaging.png" target="_blank" rel="noopener"></a></p>
<h2 id="A-Minimal-Example"><a href="#A-Minimal-Example" class="headerlink" title="A Minimal Example"></a>A Minimal Example</h2><p>本节展示了你需要在spark上训练的要素的最小部分。关于加载数据的各种方法随后就来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">JavaSparkContext sc = ...;</span><br><span class="line">JavaRDD&lt;DataSet&gt; trainingData = ...;</span><br><span class="line">MultiLayerConfiguration networkConfig = ...;</span><br><span class="line"></span><br><span class="line">//Create the TrainingMaster instance</span><br><span class="line">int examplesPerDataSetObject = 1;</span><br><span class="line">TrainingMaster trainingMaster = new ParameterAveragingTrainingMaster.Builder(examplesPerDataSetObject)</span><br><span class="line">        .(other configuration options)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">//Create the SparkDl4jMultiLayer instance</span><br><span class="line">SparkDl4jMultiLayer sparkNetwork = new SparkDl4jMultiLayer(sc, networkConfig, trainingMaster);</span><br><span class="line"></span><br><span class="line">//Fit the network using the training data:</span><br><span class="line">sparkNetwork.fit(trainingData);</span><br></pre></td></tr></table></figure></p>
<p>##Using the output from SparkDl4jMultiLayer/ComputationGraph<br>由于spark网络作为一个wrapper围绕multi layer 网络和computation graph apis，你需要最终需要从spark神经网络中获取network在训练结束之后。其原因是由于数据平行训练实际上是在训练期间一次对多个网络进行平均。这意味着这里没有一个网络直到你获得了最后的平均参数在多个worker上积累的集合的输出。<br>了解了这些，我们应该获取底层的引用不论在SparkComputationGraph和SparkDl4jMultiLayer上都使用getNetwork方法。<br>你将会注意到合适的输出将会直接返回相同的底层的网络。在这种情况下， 你可以直接使用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">JavaSparkContext sc = ...;</span><br><span class="line">JavaRDD&lt;DataSet&gt; trainingData = ...;</span><br><span class="line">MultiLayerConfiguration networkConfig = ...;</span><br><span class="line"></span><br><span class="line">//Create the TrainingMaster instance</span><br><span class="line">int examplesPerDataSetObject = 1;</span><br><span class="line">TrainingMaster trainingMaster = new ParameterAveragingTrainingMaster.Builder(examplesPerDataSetObject)</span><br><span class="line">        .(other configuration options)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">//Create the SparkDl4jMultiLayer instance</span><br><span class="line">SparkDl4jMultiLayer sparkNetwork = new SparkDl4jMultiLayer(sc, networkConfig, trainingMaster);</span><br><span class="line"></span><br><span class="line">//Fit the network using the training data:</span><br><span class="line">MultiLayerNetwork outputNetwork = sparkNetwork.fit(trainingData);</span><br></pre></td></tr></table></figure></p>
<h2 id="Configuring-the-TrainingMaster"><a href="#Configuring-the-TrainingMaster" class="headerlink" title="Configuring the TrainingMaster"></a>Configuring the TrainingMaster</h2><p>一个在DL4J中的TrainingMaster是一个接口允许多个不同的训练实现在SparkDl4jMultiLayer和SparkComputationGraph使用。<br>目前DL4J有一个实现，ParameterAveragingTrainingMaster。这个参数平均的过程在上面图片中展示了。为了创造一个，使用以下的构建模式：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TrainingMaster tm = new ParameterAveragingTrainingMaster.Builder(int dataSetObjectSize)</span><br><span class="line">            ... (your configuration here)</span><br><span class="line">            .build();</span><br></pre></td></tr></table></figure>
<p>这个ParameterAveragingTrainingMaster定义了很多的参数选项用于控制训练的执行：  </p>
<p><em>dataSetObjectSize：</em>必须值。这个在build构造函数中知名。这个值指明了有多少的列子在每一个数据集对象中。作为一个通用的规则：<br>    如果你在训练一个预处理过的数据集对象，这个将会是这个预处理的数据集的大小<br>    如果你是直接从string中进行训练，比如CSV数据经过一定的步骤后到一个RDD<dataset>那么这个将会是1.<br><em>batchSizePerWorker：</em>这个控制了每一个worker的minibatch 大小。这个和淡季训练的时候使用minibatch size有些类型。换一种方式来说：这个是对每一个参数进行更新所需要的例子数量在每一个worker中。<br><em>averagingFrequency：</em>这个控制了参数平均和重新分发的频率，根据大小为batchSizePerWorker的minibatches数量计算，通常：<br>    低平均周期（比如，averagingFrequency = 1）也许不太有效率（太多的网络通信和初始化开销，相对于计算来说。）<br>    大平均周期（比如，averagingFrequency = 200）可能会导致低性能（不同的worker实例中的参数也许会有很大的差异）<br>    Averaging periods 在5-10个minibatches也许是一个安全的选择。</dataset></p>
<p><em>workerPrefetchNumBatches：</em>Spark worker可以异步获取一定数目的minibatches，为了避免等待数据的加载。<br>    设定这个值为0来关掉提前获取。<br>    值设定为2通常是一个不错的默认值。太大的值在很多情况下并没有帮助（但是会消耗更多的内存）。<br><em>rddTrainingApproach：</em>从版本0.60开始，DL4J提供两种方法来训练从RDD<dataset>或者RDD<multidataset>.分别是：RDDTrainingApproach.Export和RDDTrainingApproach.Direct方法。<br>        Export:（Default）这个首先保存RDD<dataset>到磁盘中，使用批量和序列化的形式。这个executor然后异步加载DataSet对象，按照需求。这个方法对于大数据集和多个epochs来说比Direct方法表现要好一些。它避免了Direct方法里面切分和重新分区的开销，同样只需要更少的内存。临时文件会被删除使用TrainingMaster.deleteTempFiles()。<br>        Direct：这是DL4J早期使用的版本。它提供了更好的性能对于小数据集来说因为将会全部放进内存中。<br><em>exportDirectory</em>：只被 Export training approach 使用。这个控制了临时文件应该被保存在哪。默认是使用：{hadoop.tmp.dir}/dl4j/目录，而{hadoop.tmp.dir}是Hadoop临时目录性质的值。<br><em>storageLevelStreams</em>：只有在使用fitPaths(RDD<string>)方法的时候使用。这是DL4J将会用来保存RDD<string>的存储级别。<br>默认：StorageLevel.MEMORY_ONLY.这个默认值目前几乎在所有情况下都可以。<br><em>repartition：</em>配置何时数据应该被重新分区。ParameterAveragingTrainingMaster将会进行一个mapParititons的操作；相应的，分区的数量（以及每一个分区的值）和分区的利用有很大的关系。然而，重新分区不是一个自由的操作，有些数据必须通过网络进行复制，以下的操作是可以的：<br>    Always：默认操作，重新分区数据来保证分区的正确数量。推荐的，特别使用RDDTrainingApproach.Export（默认是0.6）或者fitPaths(RDD<string>)。<br>    Never：从不重新分区数据，无论这个分区有多不平衡。<br>    NumPartitionsWorkersDiffers：只有当分区的数量和worker的数量不一致的时候才分区。注意到即使分区的数量和总共内核的数量相同，这也不保证正确的数据集对象的就在每一个分区：有的分区也许有多的数据有的是少的数据。<br><em>repartitionStrategy:</em>哪一个重新分配的策略应该被完成。<br>    Balanced：（默认）这个是DL4J默认的重新分区的策略。它试图确保每一个分区都是均衡的对比SparkDefault选项来说。然而，在实际中，这个需要额外的count 操作来执行；在有些情况（主要是在小型的网络里，或者那些小数量的计算在每一个minibatch），这个好处也许比不上额外的执行开销。推荐的，特别在使用RDDTrainingApproach.Export 或者fitPaths（RDD<string>）<br>    SparkDefault:    这个是Spark的标准分区策略。本质上，每一个在初始化RDD中的对象被随机映射到N个中RDD中的一个。因此，这个分区也许不是最好的平衡，在小型的RDD的时候特别会有问题，特别是当它们使用预处理数据集对象并且频繁均衡时期（简单因为随机采样变化）。</string></string></string></string></dataset></multidataset></dataset></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.sevenpan.com/2018/04/15/Deep Learning on Apache Spark/" data-id="cjr7cpwwt000087rrrc9eqlgj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning4j-spark/">deeplearning4j; spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/04/20/Distributed Training- Gradients Sharing/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Distributed Training_Gradients Sharing 翻译
        
      </div>
    </a>
  
  
    <a href="/2018/04/04/RDDSpark/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">RDD Programming Guide 翻译</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algotrading-pyalgotrade/">Algotrading, pyalgotrade</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deeplearning4j-spark/">deeplearning4j; spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo-git-nginx/">hexo,git,nginx</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algotrading-pyalgotrade/" style="font-size: 10px;">Algotrading, pyalgotrade</a> <a href="/tags/deeplearning4j-spark/" style="font-size: 10px;">deeplearning4j; spark</a> <a href="/tags/hexo-git-nginx/" style="font-size: 10px;">hexo,git,nginx</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/23/RPC,REST,SOAP/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/11/07/配对交易策略RQ/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/10/17/Somethings About Pyalgotrade/">Somethings About Pyalgotrade  - the Optimizing</a>
          </li>
        
          <li>
            <a href="/2018/10/13/hexoWithGit/">Hexo With Git</a>
          </li>
        
          <li>
            <a href="/2018/04/23/Shuffle_翻译自spark_programming_guideline/">Spark Programming--- Shuffle Operations 翻译</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Pan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>